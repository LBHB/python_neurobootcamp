{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 2: Diving Deeper into Pandas\n",
    "<img src=\"https://pbs.twimg.com/media/B_1KzLlUYAIFadB.jpg:large\" width=\"200\" height=\"200\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to Day 2. Python programmers often organize their code into chunks called modules. A module contains a set of related commands to accomplish a task. Today we are going to learn two of the most useful modules for data manipulation and plotting, `pandas` and `seaborn`. \n",
    "\n",
    "First we will use a simple data set on mouse weights taken from males and females of different strains to illustrate how to obtain simple descriptive statistics, group the data, and plot. \n",
    "\n",
    "Then, we will looking some imaging statistics data from imaris and explore some more complex operations on the data.\n",
    "\n",
    "## 2.1 Loading Data using `read_csv`\n",
    "\n",
    "To start, we'll load up two modules with the `import` statement. The first is the `pandas` module, which will let us manipulate 2D tables. We refer to the `pandas` module here as `pd` as an abbreviation. The second module we load is the `numpy` module, mostly for the arithmetic functions built into it.\n",
    "\n",
    "When you load a module using `import`, all of the functions available, such as `np.mean` are now accessible to you. Modules and import statements help programmers avoid naming conflicts because you can use short, straightforward names for functions and variables without worrying that they're already taken. Matlab does not have anything equivalent to Python's module system and therefore can be harder to read. \n",
    "\n",
    "First, let's load the data up using the `pd.read_csv` function. If you want to see where the dataset is, it's in the `day-2/data/` folder. The `read_csv` function is a part of the `pandas` module, so we have to include the `pd.` in front of it so the computer knows to look in the `pandas` module to find and use this function. By using `pd.read_csv`, we return what is called a `pandas` `DataFrame`.   Most of our manipulations and plotting are going to be done on this `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "mousedata = pd.read_csv(\"data/mouseData.csv\")\n",
    "mousedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A really useful function that we can immediate call on `mousedata` is `describe`. `describe` will return summary statistics on the numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mousedata.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 A Quick Intro to functions\n",
    "\n",
    "You can think of a function as a bit of reusable code. The important thing is that you need to define the inputs (what goes into the function) and the output (what comes out of the function).\n",
    "\n",
    "Try and run the following function. What does it do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##always begin with \"def\" when defining a new function, \n",
    "##have an interface defined in the \"()\", \n",
    "##and the definition ends in \":\"\n",
    "def square_x(x):\n",
    "    out = x * x\n",
    "    return out\n",
    "\n",
    "square_x(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look a bit more closely at how the `square_x` function is written. It begins with the word `def` (short for define) followed by the name of the function, a variable named in parenthesis, and a colon. The variable is the input to the function. The colon is also a necessary part of the function definition, and it begins the code block that defines what the function does.\n",
    "\n",
    "The rest of the function consists of this code block. In Python, this block must be indented. The last line in the block contains the word 'return' followed by a variable name. This variable is the output of the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Make a new function called `cube_y` that takes `y` as an input, and returns the cube of `y`. \n",
    "\n",
    "Run `cube_y(2)` to test out your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## space for your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the most part, we actually will want multiple inputs to our function, so we can do this by supplying more inputs to our function interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mult_xy(x, y):\n",
    "    out = x * y\n",
    "    return out\n",
    "\n",
    "mult_xy(10, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Grouping\n",
    "\n",
    "Another great `pandas` function is `groupby()`. It will group a `DataFrame` by one or more columns, and let you iterate through each group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_mouse = mousedata.groupby(['Sex'])\n",
    "group_mouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: why did the `groupby` only return `Weight`? Does it make sense to do `mean_x` on our `Strain` variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "group_mouse.get_group('M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you do with `groupby()`? One way to use it is to get *aggregate measures* based on group. For example, if we wanted to get the mean weight by gender, we can use the `apply` method on our data frames to return this. First we define a simple function called `mean_x` that returns the mean (we could have just used `np.mean` here, but it makes the code a little easier to understand).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_x(x):\n",
    "    return np.mean(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use the `apply()` function to get the mean by sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mousedata.groupby(['Sex']).apply(mean_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the the `apply()` function takes a function as input and applies it to every element, in this case male and female weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Define a function to calculate the standard deviation (in numpy the function you need will be called `np.std`) and apply it to return the standard deviation of weights by `Strain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Space for your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Plotting\n",
    "\n",
    "Let's look at some ways to visualize our `DataFrame`. We are going to use a module called `seaborn` to do our plotting, because the default plot options are pretty good, so we have to do less customization.\n",
    "\n",
    "Let's just plot the distribution of weights as a histogram. How many bins does our histogram have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## import the two modules we need: matplotlib and seaborn\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "##we need this line in our notebook to make matplotlib/seaborn work with Jupyter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Histogram of weights\n",
    "sns.distplot(mousedata.Weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Look up the help for `sns.distplot`. Note that there is a long list of input variables that are set as equal to `None` or `False`. This means that these are optional input variables that, unless defined, will run at their default definitions.\n",
    "\n",
    "To practice utilizing these optional inputs, change the number of bins to 40 in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Space for your answer here.\n",
    "\n",
    "help(sns.distplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Boxplots\n",
    "\n",
    "Boxplots are super useful for looking at grouped means. Here we use the `sns.boxplot` function and group by `Sex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Boxplot\n",
    "sns.boxplot(x = \"Sex\", y=\"Weight\", data=mousedata)\n",
    "\n",
    "# Set title with matplotlib\n",
    "plt.title('Mouse weight by sex')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "Create boxplots showing the weight data measured from the 2 different strains, B6 and D2. Make sure to add a title to your plot, such as \"Weight by Strain\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Space for your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Faceting\n",
    "\n",
    "Faceting is one of the most powerful ways of exploring data. For example, we can see whether there is a `Strain` by `Sex` effect by producing *conditional* boxplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(mousedata, col=\"Strain\", row=\"Sex\")\n",
    "g = g.map(sns.distplot, \"Weight\", bins = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A more complicated example\n",
    "\n",
    "We're going to do much more manipulation and visualization with `pandas` using data taken from Imaris. Imaris is image analysis software with many sophisticated functions. Below is a confocal image taken of inner hair cells stained with antibodies against CtBP2 (a pre-synaptic ribbon marker), GluR2 (a post-synaptic receptor) and MyosinVIIA (which labels the entire hair cell). There are three color channels (red, green, and blue) which indicate the intensity of the staining for CtBP2, GluR2 and MyosinVIIa, respectively.\n",
    "\n",
    "\n",
    "## The data\n",
    "\n",
    "Up to 25 auditory nerve fibers synapse onto individual inner hair cells in\n",
    "normal-hearing individuals. However, these synapses can be permanently lost due\n",
    "to aging, exposure to noise or ototoxic drugs.  In experiments that study\n",
    "hearing loss, we need a way of quantifying the number of synapses per inner\n",
    "hair cell.\n",
    "\n",
    "One approach is to dissect the cochlea out of the experimental animals and use\n",
    "whole-mount immunohistochemistry to label the tissue with antibodies for\n",
    "pre-synaptic ribbons (CtBP2), post-synaptic receptors (GluR2) and cytoskeleton\n",
    "(Myosin VIIa). The distribution of these proteins can be captured by taking a series of\n",
    "two-dimensional images at various depths in the tissue.  These images are then\n",
    "\"stacked\" to create a three-dimensional image known as a Z-stack (since the\n",
    "third dimension is commonly referred to as the Z-axis).\n",
    "\n",
    "<table>\n",
    "\t<body>\n",
    "\t\t<tr>\n",
    "\t\t\t<td>1A. CtBP2 (pre-synaptic ribbon)</td>\n",
    "\t\t\t<td>1B. GluR2 (post-synaptic glutamate receptor)</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td><img src=\"../day-4/data/CtBP2.png\" /></td>\n",
    "\t\t\t<td><img src=\"../day-4/data/GluR2.png\" /></td>\n",
    "\t\t</tr>\n",
    "\t</body>\n",
    "</table>\n",
    "\n",
    "## The problem\n",
    "\n",
    "A functional inner hair cell synapse requires both a pre-synaptic ribbon and a\n",
    "post-synaptic glutamate receptor. The next step in our analysis is to determine\n",
    "whether each CtBP2 puncta is near a GluR2 label. \n",
    "\n",
    "This dataset was analyzed using Imaris to identify all CtBP2 puncta (white dots\n",
    "in fig. 2a). If you look closely at the composite (fig. 2b), you'll see that\n",
    "not all puncta have a glutamate receptor patch next to them (fig. 2b)! We\n",
    "should not be counting these for the purpose of analysis. So, we need to find a\n",
    "way to detect these false hits and eliminate them.\n",
    "\n",
    "<table>\n",
    "\t<body>\n",
    "\t\t<tr>\n",
    "\t\t\t<td>A. CtBP2 puncta</td>\n",
    "\t\t\t<td>B. CtBP2 puncta overlaid on GluR2</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td><img src=\"../day-4/data/CtBP2+points.png\" /></td>\n",
    "\t\t\t<td><img src=\"../day-4/data/CtBP2+GluR2+points.png\" /></td>\n",
    "\t\t</tr>\n",
    "\t</body>\n",
    "</table>\n",
    "\n",
    "One approach is to extract a fixed volume around each CtBP2 puncta (e.g., a 1um\n",
    "cube) and quantify the amount of GluR2 label in the volume. But, we don't know\n",
    "very much about the format of the data. We need to do a little exploration first.\n",
    "\n",
    "We used Imaris to detect all the \"spots\" in the CtBP2 (red) channel and compute some statistics about these spots. We've extracted the statistics file from the Imaris file into `csv` format just to make things easier. Just know that there are routines to extract this information from the file. Today we will practice exploring and visualizing the Imaris data and on Day 4 we will return to the question of how to quantify the amount of GluR2 label in a fixed volume around each CtBP2 puncta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "point_stats = pd.read_csv(\"data/points_statistics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Exploring the Imaris Statistics\n",
    "\n",
    "Because this data file was automatically generated by Imaris, we first need to figure out how it is organized.\n",
    "\n",
    "We can start taking a look at the first few rows of our summary table using `point_stats.head()`. In general, this is a really good practice to get into; sometimes our data may have a header or not, and we may have loaded the data incorrectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Show first few rows\n",
    "point_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are some things we notice? Well, there appear to be some data that describe the entire sample (such as \"Total Number of Spots\") as well as data for localized points identified by Imaris in the red channel (such as \"Area\").  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##show last few rows\n",
    "point_stats.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##show dimensions of data frame\n",
    "point_stats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see that attributes for the various traits describing a given spot (such as \"Area\" and \"Volume\") are not columns, but rather listed under the categorical column \"Name.\" If we are curious to see this full list of names, use the unique() function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "point_stats.Name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking back to the first few rows of data, it appears that ID_Object of -1 designates statistics that describe the entire sample. Let's confirm by viewing all rows with ID_Object of -1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "point_stats[point_stats[\"ID_Object\"]==-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at all of the statistics that were collected for a single spot identified by Imaris, starting with the first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "point_stats[point_stats[\"ID_Object\"]==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the raw data for Diameter of spots in the X dimension (\"Diameter X\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "point_stats[point_stats[\"Name\"]==\"Diameter X\"].head(20)\n",
    "#OR\n",
    "point_stats[point_stats[\"ID_StatisticsType\"]==237].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we only want to view the ID_Object, Value, and Name columns from this `DataFrame`, we use the `loc()` function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "point_stats.loc[:,[\"ID_Object\", \"Value\", \"Name\"]]\n",
    "#OR use iloc() to refer to the columns by their index value (i in iloc() is short for 'index')\n",
    "point_stats.iloc[:,[1,3,6]].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Use our `mean_x` function to return the mean `Intensity Max X` across the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Space for your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Pivoting\n",
    "\n",
    "Now let's create a DataFrame that is more intuitive in terms of viewing the statistics Imaris has collected for each identified spot in the red channel. We will call this DataFrame `point_stats_matrix`. To do this, use the `pivot()` function, which reshapes data based on column values. This function is extremely useful in transforming data from *long* format to *wide* format. \n",
    "\n",
    "The `pivot` method takes three arguments: `index`, which you can think of as being the rows of the data, `columns`, which specify what columns should exist in the data, and `values`, which are the actual numerical values we want in each Cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "point_stats_matrix = point_stats.pivot(index='ID_Object', columns='Name', values='Value')\n",
    "point_stats_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the statistics for the entire data set (including \"Number of spots per time point\" and \"Total number of spots\") have an ID_Object of -1. Let's remove this row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "point_stats_matrix = point_stats_matrix.drop(-1)\n",
    "point_stats_matrix.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "point_stats_matrix.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 Plotting our DataFrame for further exploration\n",
    "\n",
    "Next let's try some simple visualization, starting with a histogram of area measurements for the spots. Remember that we already imported `seaborn` and `matplotlib` above in order to use plotting functions contained in these modules, so we don't need to import them again before using the functions below. As a reminder, when we imported, we abbreviated the `seaborn` module as `sns`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(point_stats_matrix.Area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about a boxplot of Area values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(y=\"Area\", data=point_stats_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Take a look at the help for `lmplot` below and make a scatterplot comparing `Intensity Max Z` on the x axis against `Volume` on the y axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help(sns.lmplot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x='Intensity Max Z', y='Volume', fit_reg=False, data=point_stats_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9 Filtering\n",
    "\n",
    "Next we will discuss filtering. The scatterplot you created in the exercise above shows a smattering of points with an unsually large volume. Perhaps we decide that we don't trust that these are isolated points and therefore should exclude these outliers from our dataset. To do this, we will create a DataFrame named `filtered_points` that only includes spots with a volume less than 0.8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_points=point_stats_matrix[point_stats_matrix.Volume <= 0.8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create another scatterplot to confirm that your filter worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#space for new scatterplot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: what is the output of `point_stats_matrix.Volume <= 0.8`? Try it out by running the below cell. \n",
    "    \n",
    "How does this help us select the rows we want out of `point_stats_matrix`? (Hint: Think about what `True` and `False` mean.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "point_stats_matrix.Volume <= 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise\n",
    "\n",
    "Filter the `points_stats_matrix` dataset to have `Intensity Center X` > 10000 and assign it to `psm10000`. (Because of the spaces, you will have to use points_stats_matrix['Intensity Center X'] to access the column).\n",
    "\n",
    "Re-do the scatter plot of X and Y Intensity Centers to confirm that your filtering worked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##space for your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing a new column based on other columns\n",
    "\n",
    "Pandas gets extremely powerful in that you can add new columns based on calculations from other columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.10 Getting data out\n",
    "\n",
    "What if you want to save the `point_stats_matrix` DataFrame as its own csv file? Try running the code below. Where did it write the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "point_stats_matrix.to_csv(\"data/point_stats-mod.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also support for reading and writing Excel files if you need it: http://pandas.pydata.org/pandas-docs/stable/io.html#excel-files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.11 What you learned today\n",
    "\n",
    "Congrats for getting this far! You have seen lots of features of Pandas and Seaborne that let you manipulate the data and visualize it. \n",
    "\n",
    "1. `group_by`\n",
    "2. Filtering\n",
    "3. Boxplots and Scatterplots\n",
    "4. Faceting\n",
    "5. Pivoting data"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
